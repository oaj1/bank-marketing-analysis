{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a20310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries and load data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37940877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with 'unknown' values:\n",
      "job           330\n",
      "marital        80\n",
      "education    1731\n",
      "default      8597\n",
      "housing       990\n",
      "loan          990\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count 'unknown' values in each column BEFORE replacement\n",
    "unknown_counts = (df == 'unknown').sum()\n",
    "unknown_counts = unknown_counts[unknown_counts > 0]\n",
    "print(\"Columns with 'unknown' values:\")\n",
    "print(unknown_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac94604",
   "metadata": {},
   "source": [
    "## Handling `'unknown'` Values\n",
    "\n",
    "### Results: Columns with `'unknown'` Values\n",
    "- **job**: 330  \n",
    "- **marital**: 80  \n",
    "- **education**: 1,731  \n",
    "- **default**: 8,597  \n",
    "- **housing**: 990  \n",
    "- **loan**: 990  \n",
    "\n",
    "---\n",
    "\n",
    "### Best Practice for This Dataset\n",
    "Instead of dropping or imputing these values, the recommended approach is to **treat `'unknown'` as its own category**.  \n",
    "\n",
    "**Why?**\n",
    "1. **Information Value**  \n",
    "   - `'unknown'` may carry meaningful signal. For example, a client who refuses to disclose loan or housing status could behave differently from one who openly reports it.  \n",
    "   - In some cases, â€œunknownâ€ is not missing at randomâ€”it reflects a real client decision or data collection process.\n",
    "\n",
    "2. **Avoiding Bias**  \n",
    "   - Imputing with the mode (or another value) risks distorting distributions and introducing bias.  \n",
    "   - Dropping rows with unknown values would result in losing a **large number of records** (especially for `default` with ~8,600 unknowns).\n",
    "\n",
    "3. **Consistency with Categorical Encoding**  \n",
    "   - Since these variables are categorical, adding `\"unknown\"` as a legitimate category ensures the model treats it appropriately, just like `\"yes\"` or `\"no\"`.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Conclusion**:  \n",
    "For **job, marital, education, default, housing, and loan**, keep `\"unknown\"` as its own category. This preserves all records and avoids losing potential predictive signal, while staying faithful to the datasetâ€™s real-world context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecd2b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New 'prior_contact' column added to df, indicating if the client has been contacted before.\n"
     ]
    }
   ],
   "source": [
    "#make a new column to indicate if the client has been contacted before\n",
    "#pdays = number of days since the client was last contacted, 999 means the client has not been contacted before\n",
    "#so we will create a new column 'prior_contact' where 0 means no prior contact\n",
    "df['prior_contact'] = df['pdays'].apply(lambda x: 0 if x == 999 else 1)\n",
    "\n",
    "print(\"New 'prior_contact' column added to df, indicating if the client has been contacted before.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ad51e",
   "metadata": {},
   "source": [
    "## Feature Engineering: Prior Contact Indicator\n",
    "\n",
    "The column **`pdays`** represents the number of days since the client was last contacted in a previous campaign.  \n",
    "- **Special value**: `999` means the client has **not been contacted before**.  \n",
    "- Any other value means the client has been contacted previously, with the number reflecting days since that contact.\n",
    "\n",
    "---\n",
    "\n",
    "### Transformation\n",
    "We created a new binary column **`prior_contact`**:\n",
    "- **0** â†’ No prior contact (`pdays = 999`)  \n",
    "- **1** â†’ Client was contacted before (`pdays != 999`)  \n",
    "\n",
    "```python\n",
    "df['prior_contact'] = df['pdays'].apply(lambda x: 0 if x == 999 else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e31ebfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics for 'campaign':\n",
      "count    41188.000000\n",
      "mean         2.567593\n",
      "std          2.770014\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max         56.000000\n",
      "Name: campaign, dtype: float64\n",
      "we see most are between 1 and 3, with a few outliers up to 50.\n",
      "\n",
      "Descriptive statistics for 'campaign_capped':\n",
      "count    41188.000000\n",
      "mean         2.275274\n",
      "std          1.550510\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          6.000000\n",
      "Name: campaign_capped, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for 'campaign'\n",
    "print(\"Descriptive statistics for 'campaign':\")\n",
    "print(df['campaign'].describe())\n",
    "\n",
    "\n",
    "\n",
    "print((\"we see most are between 1 and 3, with a few outliers up to 50.\"))\n",
    "# Cap campaign at 6\n",
    "df['campaign_capped'] = df['campaign'].clip(upper=6)\n",
    "\n",
    "# Descriptive statistics for 'campaign_capped'\n",
    "print(\"\\nDescriptive statistics for 'campaign_capped':\")\n",
    "print(df['campaign_capped'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b401d5",
   "metadata": {},
   "source": [
    "## Descriptive Statistics for `campaign`\n",
    "\n",
    "The variable **`campaign`** represents the number of contacts performed during this campaign and for this client.  \n",
    "\n",
    "### Raw `campaign`\n",
    "- **Count**: 41,188  \n",
    "- **Mean**: ~2.57 contacts  \n",
    "- **Std (spread)**: ~2.77  \n",
    "- **Median (50%)**: 2  \n",
    "- **25% â€“ 75% (IQR)**: 1 to 3  \n",
    "- **Max**: 56  \n",
    "\n",
    "âž¡ï¸ Interpretation: Most clients were contacted **1â€“3 times**, but a few extreme outliers (up to 56) inflate the mean and standard deviation. The distribution is highly **right-skewed**.\n",
    "\n",
    "---\n",
    "\n",
    "### Capped `campaign_capped` (upper limit = 6)\n",
    "- **Mean**: ~2.28  \n",
    "- **Std (spread)**: ~1.55  \n",
    "- **Median (50%)**: 2  \n",
    "- **25% â€“ 75% (IQR)**: 1 to 3  \n",
    "- **Max**: 6  \n",
    "\n",
    "âž¡ï¸ Interpretation: By capping at 6, the influence of extreme outliers is reduced.  \n",
    "- The mean shifts closer to the median (2).  \n",
    "- The spread becomes tighter (std drops from 2.77 â†’ 1.55).  \n",
    "- The capped variable better reflects the **typical customer contact range** while avoiding unrealistic noise from rare extreme cases.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Capping Helps\n",
    "- **Exploratory Analysis**: Prevents outliers from skewing averages.  \n",
    "- **Machine Learning Prep**: Reduces noise; many models are sensitive to extreme values.  \n",
    "- **Interpretability**: Easier to explain that most customers required â‰¤6 contacts.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b45b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing the original 'campaign' column.\n",
      "Original 'campaign' column removed.\n",
      "New 'campaign_capped' column added with values capped at 6.\n"
     ]
    }
   ],
   "source": [
    "#Time to handle data outliers, we will drop the original 'campaign' column\n",
    "print(\"\\nRemoving the original 'campaign' column.\")\n",
    "df.drop(columns=['campaign'], inplace=True)\n",
    "print(\"Original 'campaign' column removed.\")\n",
    "print(\"New 'campaign_capped' column added with values capped at 6.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39d19b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    41188.000000\n",
      "mean       258.285010\n",
      "std        259.279249\n",
      "min          0.000000\n",
      "25%        102.000000\n",
      "50%        180.000000\n",
      "75%        319.000000\n",
      "max       4918.000000\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['duration'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c3d5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped duration column from df.\n"
     ]
    }
   ],
   "source": [
    "#drop duration column\n",
    "# If the 'duration' column exists, drop it; otherwise, print a message\n",
    "#dropped because it is not useful for analysis and can skew results, occurs after the last contact with the client\n",
    "if 'duration' in df.columns:\n",
    "\tdf.drop(columns=['duration'], inplace=True)\n",
    "\tprint('dropped duration column from df.')\n",
    "else:\n",
    "\tprint(\"'duration' column not found in df.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8f72c",
   "metadata": {},
   "source": [
    "## Descriptive Statistics for `duration`\n",
    "\n",
    "The variable **`duration`** represents the last contact duration (in seconds) with the client.\n",
    "\n",
    "### Results\n",
    "- **Count**: 41,188  \n",
    "- **Mean**: ~258 seconds (~4.3 minutes)  \n",
    "- **Std (spread)**: ~259 seconds (~4.3 minutes)  \n",
    "- **Median (50%)**: 180 seconds (3 minutes)  \n",
    "- **25% â€“ 75% (IQR)**: 102 to 319 seconds (~1.7 to 5.3 minutes)  \n",
    "- **Min**: 0 seconds (possible no connection or data issue)  \n",
    "- **Max**: 4,918 seconds (~82 minutes)  \n",
    "\n",
    "**Interpretation**:  \n",
    "- Most calls lasted **~2â€“5 minutes**.  \n",
    "- The mean is higher than the median, showing a **right-skewed distribution** caused by a small number of very long calls.  \n",
    "- Some calls have **0-second duration**, likely due to failed connections or placeholders.\n",
    "\n",
    "---\n",
    "\n",
    "## Why `duration` Was Dropped\n",
    "\n",
    "Although highly descriptive, the `duration` variable was **removed from the dataset** for the following reasons:\n",
    "\n",
    "1. **Data Leakage**  \n",
    "   - `duration` is only known **after** the last contact is completed.  \n",
    "   - Including it in a predictive model would give the model access to â€œfutureâ€ information unavailable at the time of prediction.  \n",
    "   - This would artificially inflate accuracy and produce misleading results.\n",
    "\n",
    "2. **Skew and Outliers**  \n",
    "   - The presence of extremely long calls (up to 82 minutes) makes the variable highly skewed, which can distort statistical analysis and model training.\n",
    "\n",
    "3. **Actionability**  \n",
    "   - Business stakeholders cannot know the call duration **before the call is made**, making it less useful for real-world targeting decisions.  \n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Conclusion**:  \n",
    "`duration` is informative for describing past campaign behavior, but it is **not valid for predictive modeling**. Dropping it ensures that the analysis focuses only on features available **before or during** the campaign, preventing data leakage and improving real-world applicability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32e48639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New 'prior_contact' column added to df, indicating if the client has been contacted before.\n"
     ]
    }
   ],
   "source": [
    "#make a new column to indicate if the client has been contacted before\n",
    "#pdays = number of days since the client was last contacted, 999 means the client has not been contacted before\n",
    "#so we will create a new column 'prior_contact' where 0 means no prior contact\n",
    "df['prior_contact'] = df['pdays'].apply(lambda x: 0 if x == 999 else 1)\n",
    "\n",
    "print(\"New 'prior_contact' column added to df, indicating if the client has been contacted before.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0c4ef",
   "metadata": {},
   "source": [
    "Creating a Prior Contact Indicator\n",
    "\n",
    "In the dataset, the column 'pdays' represents the number of days since the client\n",
    "was last contacted.\n",
    "\n",
    "- If pdays = 999 â†’ the client has never been contacted before.\n",
    "- Any other value â†’ the client was contacted previously.\n",
    "\n",
    "This raw encoding (999 as a placeholder) is not intuitive, so we create a new\n",
    "binary feature: 'prior_contact'.\n",
    "\n",
    "What I Did:\n",
    "------------\n",
    "I created a binary column:\n",
    "    0 â†’ No prior contact (pdays = 999)\n",
    "    1 â†’ Client was contacted before (pdays â‰  999)\n",
    "\n",
    "Why I Did It:\n",
    "--------------\n",
    "1. Clarity: avoids relying on the special-case code '999'.\n",
    "2. Model Readiness: binary indicators are more suitable for ML models.\n",
    "3. Interpretability: easier for humans to understand at a glance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d56a2310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 'pdays' column from df, keeping 'prior_contact' column to indicate prior contact status.\n"
     ]
    }
   ],
   "source": [
    "#lets drop the 'pdays' column\n",
    "#we will keep the 'prior_contact' column    \n",
    "df.drop(columns=['pdays'], inplace=True)\n",
    "print(\"Dropped 'pdays' column from df, keeping 'prior_contact' column to indicate prior contact status.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c10ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put target variable 'y' into binary format\n",
    "#map 'yes' to 1 and 'no' to 0\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0297a1",
   "metadata": {},
   "source": [
    "## One Hot Encoding Notes\n",
    "\n",
    "One-hot encoding is a data preprocessing step used to convert categorical variables (like \"job\", \"education\", \"month\", etc.) into a format that machine learning algorithms can understand.\n",
    "\n",
    "Most machine learning models (especially logistic regression, decision trees, etc.) can't work directly with text labels â€” they need numbers\n",
    "\n",
    "\n",
    "\n",
    "## Why Use In My Code?\n",
    "One-hot encoding creates a new column for each unique value in a categorical column and assigns a 1 or 0 to indicate presence.\n",
    "\n",
    "This avoids introducing false ordinal relationships (like if you encoded them as 0, 1, 2), which would wrongly suggest that \"technician\" > \"admin.\"\n",
    "\n",
    "I'm building a model to predict whether someone will subscribe to a term deposit (a classification task).\n",
    "\n",
    "Many of the features are categorical:\n",
    "\n",
    "['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    " 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    " \n",
    " To make these usable in My logistic regression or other ML model, I must convert them to numbers â€” and one-hot encoding is the standard, safe way to do it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47ed49df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All categorical variables in df have been converted to dummy variables.\n",
      "Converted categorical columns to dummy variables:\n",
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
      "\n",
      "New columns created by one-hot encoding:\n",
      "['contact_telephone', 'day_of_week_mon', 'day_of_week_thu', 'day_of_week_tue', 'day_of_week_wed', 'default_unknown', 'default_yes', 'education_basic.6y', 'education_basic.9y', 'education_high.school', 'education_illiterate', 'education_professional.course', 'education_university.degree', 'education_unknown', 'housing_unknown', 'housing_yes', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'loan_unknown', 'loan_yes', 'marital_married', 'marital_single', 'marital_unknown', 'month_aug', 'month_dec', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'poutcome_nonexistent', 'poutcome_success']\n"
     ]
    }
   ],
   "source": [
    "# Define the original categorical columns\n",
    "categorical_cols = [\n",
    "    'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "    'contact', 'month', 'day_of_week', 'poutcome'\n",
    "]\n",
    "\n",
    "# Make a copy of df BEFORE encoding for comparison later\n",
    "df_beforeEncoding = df.copy()\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "df_afterEncoding = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Informative messages\n",
    "print(\"All categorical variables in df have been converted to dummy variables.\")\n",
    "print(\"Converted categorical columns to dummy variables:\")\n",
    "print(categorical_cols)\n",
    "print()\n",
    "\n",
    "# Compare column sets to find new dummy variables created\n",
    "new_columns = set(df_afterEncoding.columns) - set(df_beforeEncoding.columns)\n",
    "print(\"New columns created by one-hot encoding:\")\n",
    "print(sorted(new_columns))  # sorted to make it easier to read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468c6e2",
   "metadata": {},
   "source": [
    "## ðŸ“Š DataFrames Overview\n",
    "\n",
    "### 1. `df_beforeEncoding`\n",
    "This is the **original** DataFrame, with some basic cleaning applied. It includes the following **categorical columns** that require encoding:\n",
    "\n",
    "```python\n",
    "['job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    " 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7396e99",
   "metadata": {},
   "source": [
    "## ðŸ“Š DataFrames Overview\n",
    "\n",
    "### 2. `df_afterEncoding`\n",
    "This is the **updated** DataFrame, with One Hot Encoding applied. It includes the following **Numerical columns** that have been encoded:\n",
    "\n",
    "```python\n",
    "['contact_telephone', 'day_of_week_mon', 'day_of_week_thu', 'day_of_week_tue', 'day_of_week_wed', 'default_unknown', 'default_yes', 'education_basic.6y', 'education_basic.9y', 'education_high.school', 'education_illiterate', 'education_professional.course', 'education_university.degree', 'education_unknown', 'housing_unknown', 'housing_yes', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'loan_unknown', 'loan_yes', 'marital_married', 'marital_single', 'marital_unknown', 'month_aug', 'month_dec', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'poutcome_nonexistent', 'poutcome_success']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2faaf097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping duplicates: (41188, 53)\n",
      "\n",
      "No duplicate columns found after encoding.\n",
      "\n",
      "Number of duplicate rows in df_afterEncoding: 1860\n",
      "Consider removing duplicate rows to ensure data integrity.\n",
      "\n",
      "Shape after dropping duplicates: (39328, 53)\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicate values, columns, data redundancy\n",
    "\n",
    "\n",
    "print(f\"Shape before dropping duplicates: {df_afterEncoding.shape}\")\n",
    "with_duplicates = df_afterEncoding.columns[df_afterEncoding.columns.duplicated()].tolist()\n",
    "\n",
    "if with_duplicates:\n",
    "    print(\"\\nDuplicate columns found after encoding:\")\n",
    "    print(with_duplicates)\n",
    "else:\n",
    "    print(\"\\nNo duplicate columns found after encoding.\")\n",
    "\n",
    "duplicate_values = df_afterEncoding.duplicated().sum()\n",
    "\n",
    "\n",
    "print(f\"\\nNumber of duplicate rows in df_afterEncoding: {duplicate_values}\")\n",
    "if duplicate_values > 0:\n",
    "    print(\"Consider removing duplicate rows to ensure data integrity.\")\n",
    "    df_afterEncoding.drop_duplicates(inplace=True)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_afterEncoding.\")\n",
    "\n",
    "print()\n",
    "print(f\"Shape after dropping duplicates: {df_afterEncoding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49568289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'cleaned_bank.csv'.\n"
     ]
    }
   ],
   "source": [
    "df_afterEncoding.to_csv('cleaned_bank.csv', index=False)\n",
    "print(\"Cleaned data saved to 'cleaned_bank.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
