{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3144951",
   "metadata": {},
   "source": [
    "## Logistic Regression ‚Äì Using More Intuitive Feature Selection for Easier Interpretation\n",
    "\n",
    "In this step, I‚Äôm transitioning from the EDA phase into building a logistic regression model.  \n",
    "Instead of using the full one-hot encoded dataset with 50+ features, I‚Äôm intentionally **selecting a smaller, more interpretable set of features** that are both relevant and easier to explain in terms of their relationship to the target variable (`y`).\n",
    "\n",
    "**Rationale for this approach:**\n",
    "- **Interpretability:** A smaller set of features makes it easier to understand how each variable influences the prediction.\n",
    "- **Simplicity:** Reduces complexity and multicollinearity issues that can occur with many dummy variables.\n",
    "- **Focus on meaningful predictors:** Using variables that have clear business or contextual meaning.\n",
    "\n",
    "**Features selected:**\n",
    "- `age` ‚Äì Age of the individual.\n",
    "- `previous` ‚Äì Number of previous contacts with the client.\n",
    "- `emp.var.rate` ‚Äì Employment variation rate.\n",
    "- `cons.price.idx` ‚Äì Consumer price index.\n",
    "- `cons.conf.idx` ‚Äì Consumer confidence index.\n",
    "- `euribor3m` ‚Äì 3-month Euribor interest rate.\n",
    "- `nr.employed` ‚Äì Number of employees.\n",
    "- `prior_contact` ‚Äì Binary flag if the client had been previously contacted.\n",
    "- `campaign_capped` ‚Äì Number of contacts made during the current campaign (capped).\n",
    "\n",
    "**Target variable:**\n",
    "- `y` ‚Äì Binary outcome indicating if the client subscribed to the term deposit (1) or not (0).\n",
    "\n",
    "**Next steps:**\n",
    "1. Split data into training and testing sets.\n",
    "2. Scale numeric features for logistic regression.\n",
    "3. Train the model.\n",
    "4. Evaluate performance (accuracy, classification report, confusion matrix).\n",
    "5. Optionally, interpret coefficients to understand feature importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a02de0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first import pandas and read from the cleaned dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('cleaned_bank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4860db",
   "metadata": {},
   "source": [
    "1.Feature selection (My reduced intuitive feature list).\n",
    "\n",
    "2.Train/test split.\n",
    "\n",
    "3.Scaling.\n",
    "\n",
    "4.Model fitting.\n",
    "\n",
    "5.Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47f71f",
   "metadata": {},
   "source": [
    "1.) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d42889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection for logistic regression\n",
    "#We will use the following features for our logistic regression model:\n",
    "#1. age, previous, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed\n",
    "\n",
    "features_to_keep = [\n",
    "    'age',\n",
    "    'previous',\n",
    "    'emp.var.rate',\n",
    "    'cons.price.idx',\n",
    "    'cons.conf.idx',\n",
    "    'euribor3m',\n",
    "    'nr.employed',\n",
    "    'prior_contact',\n",
    "    'campaign_capped'\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934ecd9",
   "metadata": {},
   "source": [
    "### Feature Selection for Logistic Regression\n",
    "\n",
    "In this step, we define the set of features that will be used as inputs for our logistic regression model.  \n",
    "The selected features are chosen because they capture key aspects of the client‚Äôs profile, economic indicators,  \n",
    "and campaign history that may influence the outcome.\n",
    "\n",
    "**Selected Features:**\n",
    "1. **age** ‚Äì Age of the client.  \n",
    "2. **previous** ‚Äì Number of previous contacts with the client.  \n",
    "3. **emp.var.rate** ‚Äì Employment variation rate (economic indicator).  \n",
    "4. **cons.price.idx** ‚Äì Consumer price index.  \n",
    "5. **cons.conf.idx** ‚Äì Consumer confidence index.  \n",
    "6. **euribor3m** ‚Äì Euribor 3-month rate (financial indicator).  \n",
    "7. **nr.employed** ‚Äì Number of employees (macro-level economic indicator).  \n",
    "8. **prior_contact** ‚Äì Indicates whether the client was contacted previously in the campaign.  \n",
    "9. **campaign_capped** ‚Äì A capped version of the campaign variable to limit outliers in contact attempts.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db9b5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only selected features compare against the target variable 'y'\n",
    "X = df[features_to_keep].copy () # Features for the model\n",
    "y = df['y'].astype(int)  # Convert target variable to integer (0 or 1)\n",
    "\n",
    "#type(X), type(y)\n",
    "# ensure binary columns are ints (0/1) not bool/object\n",
    "X[['prior_contact', 'campaign_capped']] = X[['prior_contact', 'campaign_capped']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a5c28",
   "metadata": {},
   "source": [
    "### Preparing Features and Target Variable for Logistic Regression\n",
    "\n",
    "After selecting the features, the next step is to separate the input variables (**X**) and the target variable (**y**) to train our logistic regression model.\n",
    "\n",
    "**Steps:**\n",
    "1. **Select Features (X):**  \n",
    "   - `X = df[features_to_keep].copy()` creates a new dataframe containing only the chosen features.  \n",
    "   - This prevents accidental changes to the original dataframe while modeling.  \n",
    "\n",
    "2. **Define Target (y):**  \n",
    "   - `y = df['y'].astype(int)` extracts the target column (`y`) and converts it to integers (0 or 1).  \n",
    "   - This ensures the target is properly formatted for binary classification.  \n",
    "\n",
    "3. **Ensure Correct Data Types for Binary Features:**  \n",
    "   - `X[['prior_contact', 'campaign_capped']] = ... .astype('category')`  \n",
    "   - Converts these features into categorical variables (instead of boolean or object).  \n",
    "   - This helps the model and preprocessing pipelines treat them correctly.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb972c7f",
   "metadata": {},
   "source": [
    "Identify Column Types\n",
    "Identify which columns are numeric and which are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd3c313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['age', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "Categorical columns: ['prior_contact', 'campaign_capped']\n",
      "target variable: y 0 or 1: int32\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print('target variable:', y.name + ' 0 or 1:', y.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63f7a7",
   "metadata": {},
   "source": [
    "2.) Train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60d46fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31462, 9) (7866, 9) (31462,) (7866,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# test size 20% of rows go to test set, 80% to train set\n",
    "# random_state ensures reproducibility of the split\n",
    "# stratify ensures that the proportion of classes in y is maintained in both train and test sets\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "#\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c0754",
   "metadata": {},
   "source": [
    "**Train/Test Split ‚Äî Output Summary**\n",
    "-------------------------------------\n",
    "\n",
    "**X_train**: feature matrix used to train the model (rows = training examples, cols = features).  \n",
    "**y_train**: target labels for those training examples.  \n",
    "**X_test**: feature matrix held out for evaluating the trained model.  \n",
    "**y_test**: true labels for the test rows used only to measure performance.  \n",
    "\n",
    "---\n",
    "\n",
    "### üîë Key differences and why they matter\n",
    "- **Purpose:**  \n",
    "  - `X_train` / `y_train` ‚Üí learn model parameters.  \n",
    "  - `X_test` / `y_test` ‚Üí assess how the learned model generalizes to unseen data.  \n",
    "\n",
    "---\n",
    "\n",
    "### üìä What the Output Means\n",
    "- `X_train` ‚Üí 31,462 rows √ó 9 features (80% of the data)  \n",
    "- `X_test`  ‚Üí  7,866 rows √ó 9 features (20% of the data)  \n",
    "- `y_train` ‚Üí 31,462 labels (matches X_train rows)  \n",
    "- `y_test`  ‚Üí  7,866 labels (matches X_test rows)  \n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Why the Numbers Make Sense\n",
    "- **Total rows:**  \n",
    "  31,462 + 7,866 = 39,328 total rows in dataset.  \n",
    "\n",
    "- **80/20 split check:**  \n",
    "  - Train: 39,328 √ó 0.8 ‚âà 31,462  ‚úÖ  \n",
    "  - Test:  39,328 √ó 0.2 ‚âà  7,866  ‚úÖ  \n",
    "\n",
    "- **Same features in train/test:**  \n",
    "  Both X_train and X_test have exactly 9 columns (features).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d50294",
   "metadata": {},
   "source": [
    "Now I need to scale continous features, fit logistic regression on X_train/y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b616cd",
   "metadata": {},
   "source": [
    "3.) Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f0b35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets do some preprocessing of the data\n",
    "#Preprocessing is important for machine learning models to ensure that the data is in the right format\n",
    "#Preprocessing = cleaning, imputing, encoding, scaling, etc.\n",
    "#Typical steps, 1.) train test split, 2.) categorical encoding, 3.) scaling, 4.) model training\n",
    "\n",
    "#We already did the train test split above, now we will do categorical encoding and scaling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#time to do one-hot encoding for categorical features\n",
    "preprocessor = ColumnTransformer (\n",
    "\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), numeric_cols),  # Scale numeric columns\n",
    "        \n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols) # One-hot encode categorical columns, ignore unknown categories during transformation\n",
    "    ]\n",
    "    , remainder='passthrough'  # Keep numeric columns as they are\n",
    ")\n",
    "\n",
    "#Now we do a pipeline to combine preprocessing with the model\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),  # Preprocessing step\n",
    "    ('clf', LogisticRegression(class_weight = 'balanced',max_iter=1000))  # Logistic Regression model, balannced class weights to handle class imbalance\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a2bcf",
   "metadata": {},
   "source": [
    "Pipeline: chains preprocessing steps and a final estimator so you call fit/transform/predict once. It guarantees transforms are applied in the correct order and prevents data leakage (you fit transforms only on X_train).\n",
    "\n",
    "ColumnTransformer: applies different transforms to different column subsets (e.g., scale numeric, one-hot encode categorical) and returns a single feature matrix the estimator can use.\n",
    "\n",
    "Benefits: simpler code, fewer mistakes (no manual concat/typos), reproducible transforms saved with the model, and safe train/test separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531124a6",
   "metadata": {},
   "source": [
    "4.) Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "483736f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;previous&#x27;,\n",
       "                                                   &#x27;emp.var.rate&#x27;,\n",
       "                                                   &#x27;cons.price.idx&#x27;,\n",
       "                                                   &#x27;cons.conf.idx&#x27;, &#x27;euribor3m&#x27;,\n",
       "                                                   &#x27;nr.employed&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;prior_contact&#x27;,\n",
       "                                                   &#x27;campaign_capped&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;previous&#x27;,\n",
       "                                                   &#x27;emp.var.rate&#x27;,\n",
       "                                                   &#x27;cons.price.idx&#x27;,\n",
       "                                                   &#x27;cons.conf.idx&#x27;, &#x27;euribor3m&#x27;,\n",
       "                                                   &#x27;nr.employed&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;prior_contact&#x27;,\n",
       "                                                   &#x27;campaign_capped&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;previous&#x27;, &#x27;emp.var.rate&#x27;,\n",
       "                                  &#x27;cons.price.idx&#x27;, &#x27;cons.conf.idx&#x27;,\n",
       "                                  &#x27;euribor3m&#x27;, &#x27;nr.employed&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;prior_contact&#x27;, &#x27;campaign_capped&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;previous&#x27;, &#x27;emp.var.rate&#x27;, &#x27;cons.price.idx&#x27;, &#x27;cons.conf.idx&#x27;, &#x27;euribor3m&#x27;, &#x27;nr.employed&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;prior_contact&#x27;, &#x27;campaign_capped&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('num', StandardScaler(),\n",
       "                                                  ['age', 'previous',\n",
       "                                                   'emp.var.rate',\n",
       "                                                   'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['prior_contact',\n",
       "                                                   'campaign_capped'])])),\n",
       "                ('clf',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now I need to fit the model to the training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1633f",
   "metadata": {},
   "source": [
    "### Understanding `pipeline.fit(X_train, y_train)`\n",
    "\n",
    "When you call `pipeline.fit(X_train, y_train)`, scikit-learn runs each step of the pipeline in order:\n",
    "\n",
    "1. **Preprocessing Step (`preprocessor`)**  \n",
    "   - Numeric columns ‚Üí scaled using `StandardScaler()` (mean = 0, std = 1).  \n",
    "   - Categorical columns ‚Üí encoded using `OneHotEncoder()` (creates binary columns for categories).  \n",
    "   - Any columns not specified remain unchanged (`remainder='passthrough'`).  \n",
    "   - The preprocessor *learns* from the training data (e.g., category values, scaling parameters).\n",
    "\n",
    "2. **Model Training Step (`LogisticRegression`)**  \n",
    "   - The transformed training data is passed into the logistic regression model.  \n",
    "   - The model learns patterns between features (`X_train`) and the target (`y_train`).  \n",
    "   - Using `class_weight='balanced'` tells the model to adjust for class imbalance by giving more weight to underrepresented classes.  \n",
    "\n",
    "---\n",
    "\n",
    "### Why use a Pipeline?\n",
    "- **Prevents data leakage**: Preprocessing is learned only from training data and applied consistently to new/test data.  \n",
    "- **Cleaner code**: One object handles all steps instead of writing them separately.  \n",
    "- **Consistency**: Guarantees that the same transformations are applied during training and prediction.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **In short:**  \n",
    "`pipeline.fit(X_train, y_train)` means *‚Äúfit the preprocessing steps on the training data, transform it, and then train the logistic regression model on the processed data.‚Äù*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1295cdb",
   "metadata": {},
   "source": [
    "5.) Evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
