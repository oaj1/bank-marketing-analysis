{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3144951",
   "metadata": {},
   "source": [
    "## Logistic Regression â€“ Using More Intuitive Feature Selection for Easier Interpretation\n",
    "\n",
    "In this step, Iâ€™m transitioning from the EDA phase into building a logistic regression model.  \n",
    "Instead of using the full one-hot encoded dataset with 50+ features, Iâ€™m intentionally **selecting a smaller, more interpretable set of features** that are both relevant and easier to explain in terms of their relationship to the target variable (`y`).\n",
    "\n",
    "**Rationale for this approach:**\n",
    "- **Interpretability:** A smaller set of features makes it easier to understand how each variable influences the prediction.\n",
    "- **Simplicity:** Reduces complexity and multicollinearity issues that can occur with many dummy variables.\n",
    "- **Focus on meaningful predictors:** Using variables that have clear business or contextual meaning.\n",
    "\n",
    "**Features selected:**\n",
    "- `age` â€“ Age of the individual.\n",
    "- `previous` â€“ Number of previous contacts with the client.\n",
    "- `emp.var.rate` â€“ Employment variation rate.\n",
    "- `cons.price.idx` â€“ Consumer price index.\n",
    "- `cons.conf.idx` â€“ Consumer confidence index.\n",
    "- `euribor3m` â€“ 3-month Euribor interest rate.\n",
    "- `nr.employed` â€“ Number of employees.\n",
    "- `prior_contact` â€“ Binary flag if the client had been previously contacted.\n",
    "- `campaign_capped` â€“ Number of contacts made during the current campaign (capped).\n",
    "\n",
    "**Target variable:**\n",
    "- `y` â€“ Binary outcome indicating if the client subscribed to the term deposit (1) or not (0).\n",
    "\n",
    "**Next steps:**\n",
    "1. Split data into training and testing sets.\n",
    "2. Scale numeric features for logistic regression.\n",
    "3. Train the model.\n",
    "4. Evaluate performance (accuracy, classification report, confusion matrix).\n",
    "5. Optionally, interpret coefficients to understand feature importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02de0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first import pandas and read from the cleaned dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('cleaned_bank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4860db",
   "metadata": {},
   "source": [
    "1.Feature selection (My reduced intuitive feature list).\n",
    "\n",
    "2.Train/test split.\n",
    "\n",
    "3.Scaling.\n",
    "\n",
    "4.Model fitting.\n",
    "\n",
    "5.Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d42889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection for logistic regression\n",
    "#We will use the following features for our logistic regression model:\n",
    "#1. age, previous, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed\n",
    "\n",
    "features_to_keep = [\n",
    "    'age',\n",
    "    'previous',\n",
    "    'emp.var.rate',\n",
    "    'cons.price.idx',\n",
    "    'cons.conf.idx',\n",
    "    'euribor3m',\n",
    "    'nr.employed',\n",
    "    'prior_contact',\n",
    "    'campaign_capped'\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9b5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only selected features compare against the target variable 'y'\n",
    "X = df[features_to_keep].copy () # Features for the model\n",
    "y = df['y'].astype(int)  # Convert target variable to integer (0 or 1)\n",
    "\n",
    "type(X), type(y)\n",
    "# ensure binary columns are ints (0/1) not bool/object\n",
    "X[['prior_contact', 'campaign_capped']] = X[['prior_contact', 'campaign_capped']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb972c7f",
   "metadata": {},
   "source": [
    "Identify Column Types\n",
    "Identify which columns are numeric and which are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3c313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['age', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "Categorical columns: ['prior_contact', 'campaign_capped']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63f7a7",
   "metadata": {},
   "source": [
    "Now Lets start the Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d46fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31462, 9) (7866, 9) (31462,) (7866,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training and testing sets\n",
    "# test size 20% of rows go to test set, 80% to train set\n",
    "# random_state ensures reproducibility of the split\n",
    "# stratify ensures that the proportion of classes in y is maintained in both train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "#\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c0754",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "========================================\n",
    "   Train/Test Split â€” Output Summary\n",
    "========================================\n",
    "\n",
    "ðŸ“Š What the Output Means\n",
    "------------------------\n",
    "â€¢ X_train â†’ 31,462 rows Ã— 9 features (80% of the data)\n",
    "â€¢ X_test  â†’  7,866 rows Ã— 9 features (20% of the data)\n",
    "â€¢ y_train â†’ 31,462 labels (matches X_train rows)\n",
    "â€¢ y_test  â†’  7,866 labels (matches X_test rows)\n",
    "\n",
    "ðŸ§® Why the Numbers Make Sense\n",
    "-----------------------------\n",
    "â€¢ Total rows:\n",
    "    31,462 + 7,866 = 39,328 total rows in dataset.\n",
    "\n",
    "â€¢ 80/20 split check:\n",
    "    Train: 39,328 Ã— 0.8 â‰ˆ 31,462  âœ…\n",
    "    Test:  39,328 Ã— 0.2 â‰ˆ  7,866  âœ…\n",
    "\n",
    "â€¢ Same features in train/test:\n",
    "    Both X_train and X_test have exactly 9 columns (features).\n",
    "========================================\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
