{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3144951",
   "metadata": {},
   "source": [
    "## Logistic Regression â€“ Using More Intuitive Feature Selection for Easier Interpretation\n",
    "\n",
    "In this step, Iâ€™m transitioning from the EDA phase into building a logistic regression model.  \n",
    "Instead of using the full one-hot encoded dataset with 50+ features, Iâ€™m intentionally **selecting a smaller, more interpretable set of features** that are both relevant and easier to explain in terms of their relationship to the target variable (`y`).\n",
    "\n",
    "**Rationale for this approach:**\n",
    "- **Interpretability:** A smaller set of features makes it easier to understand how each variable influences the prediction.\n",
    "- **Simplicity:** Reduces complexity and multicollinearity issues that can occur with many dummy variables.\n",
    "- **Focus on meaningful predictors:** Using variables that have clear business or contextual meaning.\n",
    "\n",
    "**Features selected:**\n",
    "- `age` â€“ Age of the individual.\n",
    "- `previous` â€“ Number of previous contacts with the client.\n",
    "- `emp.var.rate` â€“ Employment variation rate.\n",
    "- `cons.price.idx` â€“ Consumer price index.\n",
    "- `cons.conf.idx` â€“ Consumer confidence index.\n",
    "- `euribor3m` â€“ 3-month Euribor interest rate.\n",
    "- `nr.employed` â€“ Number of employees.\n",
    "- `prior_contact` â€“ Binary flag if the client had been previously contacted.\n",
    "- `campaign_capped` â€“ Number of contacts made during the current campaign (capped).\n",
    "\n",
    "**Target variable:**\n",
    "- `y` â€“ Binary outcome indicating if the client subscribed to the term deposit (1) or not (0).\n",
    "\n",
    "**Next steps:**\n",
    "1. Split data into training and testing sets.\n",
    "2. Scale numeric features for logistic regression.\n",
    "3. Train the model.\n",
    "4. Evaluate performance (accuracy, classification report, confusion matrix).\n",
    "5. Optionally, interpret coefficients to understand feature importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a02de0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first import pandas and read from the cleaned dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('cleaned_bank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4860db",
   "metadata": {},
   "source": [
    "1.Feature selection (My reduced intuitive feature list).\n",
    "\n",
    "2.Train/test split.\n",
    "\n",
    "3.Scaling.\n",
    "\n",
    "4.Model fitting.\n",
    "\n",
    "5.Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47f71f",
   "metadata": {},
   "source": [
    "1.) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d42889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection for logistic regression\n",
    "#We will use the following features for our logistic regression model:\n",
    "#1. age, previous, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed\n",
    "\n",
    "features_to_keep = [\n",
    "    'age',\n",
    "    'previous',\n",
    "    'emp.var.rate',\n",
    "    'cons.price.idx',\n",
    "    'cons.conf.idx',\n",
    "    'euribor3m',\n",
    "    'nr.employed',\n",
    "    'prior_contact',\n",
    "    'campaign_capped'\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934ecd9",
   "metadata": {},
   "source": [
    "### Feature Selection for Logistic Regression\n",
    "\n",
    "In this step, we define the set of features that will be used as inputs for our logistic regression model.  \n",
    "The selected features are chosen because they capture key aspects of the clientâ€™s profile, economic indicators,  \n",
    "and campaign history that may influence the outcome.\n",
    "\n",
    "**Selected Features:**\n",
    "1. **age** â€“ Age of the client.  \n",
    "2. **previous** â€“ Number of previous contacts with the client.  \n",
    "3. **emp.var.rate** â€“ Employment variation rate (economic indicator).  \n",
    "4. **cons.price.idx** â€“ Consumer price index.  \n",
    "5. **cons.conf.idx** â€“ Consumer confidence index.  \n",
    "6. **euribor3m** â€“ Euribor 3-month rate (financial indicator).  \n",
    "7. **nr.employed** â€“ Number of employees (macro-level economic indicator).  \n",
    "8. **prior_contact** â€“ Indicates whether the client was contacted previously in the campaign.  \n",
    "9. **campaign_capped** â€“ A capped version of the campaign variable to limit outliers in contact attempts.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db9b5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only selected features compare against the target variable 'y'\n",
    "X = df[features_to_keep].copy () # Features for the model\n",
    "y = df['y'].astype(int)  # Convert target variable to integer (0 or 1)\n",
    "\n",
    "#type(X), type(y)\n",
    "# ensure binary columns are ints (0/1) not bool/object\n",
    "X[['prior_contact', 'campaign_capped']] = X[['prior_contact', 'campaign_capped']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a5c28",
   "metadata": {},
   "source": [
    "### Preparing Features and Target Variable for Logistic Regression\n",
    "\n",
    "After selecting the features, the next step is to separate the input variables (**X**) and the target variable (**y**) to train our logistic regression model.\n",
    "\n",
    "**Steps:**\n",
    "1. **Select Features (X):**  \n",
    "   - `X = df[features_to_keep].copy()` creates a new dataframe containing only the chosen features.  \n",
    "   - This prevents accidental changes to the original dataframe while modeling.  \n",
    "\n",
    "2. **Define Target (y):**  \n",
    "   - `y = df['y'].astype(int)` extracts the target column (`y`) and converts it to integers (0 or 1).  \n",
    "   - This ensures the target is properly formatted for binary classification.  \n",
    "\n",
    "3. **Ensure Correct Data Types for Binary Features:**  \n",
    "   - `X[['prior_contact', 'campaign_capped']] = ... .astype('category')`  \n",
    "   - Converts these features into categorical variables (instead of boolean or object).  \n",
    "   - This helps the model and preprocessing pipelines treat them correctly.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb972c7f",
   "metadata": {},
   "source": [
    "Identify Column Types\n",
    "Identify which columns are numeric and which are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd3c313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['age', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "Categorical columns: ['prior_contact', 'campaign_capped']\n",
      "target variable: y 0 or 1: int32\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print('target variable:', y.name + ' 0 or 1:', y.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63f7a7",
   "metadata": {},
   "source": [
    "2.) Train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60d46fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31462, 9) (7866, 9) (31462,) (7866,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# test size 20% of rows go to test set, 80% to train set\n",
    "# random_state ensures reproducibility of the split\n",
    "# stratify ensures that the proportion of classes in y is maintained in both train and test sets\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n",
    "\n",
    "#\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c0754",
   "metadata": {},
   "source": [
    "**Train/Test Split â€” Output Summary**\n",
    "-------------------------------------\n",
    "\n",
    "**X_train**: feature matrix used to train the model (rows = training examples, cols = features).  \n",
    "**y_train**: target labels for those training examples.  \n",
    "**X_test**: feature matrix held out for evaluating the trained model.  \n",
    "**y_test**: true labels for the test rows used only to measure performance.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”‘ Key differences and why they matter\n",
    "- **Purpose:**  \n",
    "  - `X_train` / `y_train` â†’ learn model parameters.  \n",
    "  - `X_test` / `y_test` â†’ assess how the learned model generalizes to unseen data.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š What the Output Means\n",
    "- `X_train` â†’ 31,462 rows Ã— 9 features (80% of the data)  \n",
    "- `X_test`  â†’  7,866 rows Ã— 9 features (20% of the data)  \n",
    "- `y_train` â†’ 31,462 labels (matches X_train rows)  \n",
    "- `y_test`  â†’  7,866 labels (matches X_test rows)  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§® Why the Numbers Make Sense\n",
    "- **Total rows:**  \n",
    "  31,462 + 7,866 = 39,328 total rows in dataset.  \n",
    "\n",
    "- **80/20 split check:**  \n",
    "  - Train: 39,328 Ã— 0.8 â‰ˆ 31,462  âœ…  \n",
    "  - Test:  39,328 Ã— 0.2 â‰ˆ  7,866  âœ…  \n",
    "\n",
    "- **Same features in train/test:**  \n",
    "  Both X_train and X_test have exactly 9 columns (features).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d50294",
   "metadata": {},
   "source": [
    "Now I need to scale continous features, fit logistic regression on X_train/y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b616cd",
   "metadata": {},
   "source": [
    "3.) Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f0b35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets do some preprocessing of the data\n",
    "#Preprocessing is important for machine learning models to ensure that the data is in the right format\n",
    "#Preprocessing = cleaning, imputing, encoding, scaling, etc.\n",
    "#Typical steps, 1.) train test split, 2.) categorical encoding, 3.) scaling, 4.) model training\n",
    "\n",
    "#We already did the train test split above, now we will do categorical encoding and scaling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#time to do one-hot encoding for categorical features\n",
    "preprocessor = ColumnTransformer (\n",
    "\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), numeric_cols),  # Scale numeric columns\n",
    "        \n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols) # One-hot encode categorical columns, ignore unknown categories during transformation\n",
    "    ]\n",
    "    , remainder='passthrough'  # Keep numeric columns as they are\n",
    ")\n",
    "\n",
    "#Now we do a pipeline to combine preprocessing with the model\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),  # Preprocessing step\n",
    "    ('clf', LogisticRegression(class_weight = 'balanced',max_iter=1000))  # Logistic Regression model, balannced class weights to handle class imbalance\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531124a6",
   "metadata": {},
   "source": [
    "4.) Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1295cdb",
   "metadata": {},
   "source": [
    "5.) Evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
